{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name isaac ndirangu muturi\n",
    "full time student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SyriaTel Customer Churn\n",
    "\n",
    "Links to an external site.\n",
    "\n",
    "Build a classifier to predict whether a customer will (\"soon\") stop doing business with SyriaTel, a telecommunications company. This is a binary classification problem.\n",
    "\n",
    "Most naturally, your audience here would be the telecom business itself, interested in reducing how much money is lost because of customers who don't stick around very long. The question you can ask is: are there any predictable patterns here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graded elements for the Jupyter Notebook are:\n",
    "\n",
    "Business Understanding\n",
    "\n",
    "Business Problem\n",
    "\n",
    "Import libraries and modules\n",
    "\n",
    "Data Understanding\n",
    "\n",
    "Data Preparation\n",
    "\n",
    "Explanatory Data Analysis (EDA)\n",
    "\n",
    "Modeling\n",
    "\n",
    "Evaluation\n",
    "\n",
    "Code Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a data scientist assigned to investigate customer churn for SyriaTel, my main objective is to analyze the available data and develop a predictive classifier that can accurately determine whether a customer is likely to terminate their relationship with the telecommunications company. By understanding the underlying patterns and reasons behind customer churn, our aim is to assist SyriaTel in reducing financial losses and implementing targeted retention strategies. Through comprehensive data analysis and modeling techniques, we can identify key factors influencing churn and provide actionable insights to the business.\n",
    "\n",
    "To achieve this goal, I will begin by conducting a thorough examination of the dataset, encompassing customer demographics, usage patterns, billing information, and customer service interactions. This exploratory analysis will enable me to gain a deep understanding of the data, identifying potential features that have a significant impact on customer churn. By leveraging statistical techniques and visualization methods, I can uncover correlations and patterns that will serve as the foundation for the subsequent modeling phase.\n",
    "\n",
    "Once the dataset has been carefully examined, I will preprocess the data to handle missing values, encode categorical variables, and normalize numerical features. This preprocessing step is crucial to ensure the dataset is suitable for modeling, as it minimizes bias and enhances the quality of the input data. Additionally, I will employ feature selection techniques to identify the most relevant variables or engineer new features that can provide valuable insights into customer churn. This process will involve assessing feature importance, conducting correlation analysis, and incorporating domain knowledge expertise to select the most informative set of features.\n",
    "\n",
    "After feature selection and engineering, I will select an appropriate machine learning algorithm for the classification task. Depending on the nature of the data and the problem at hand, algorithms such as logistic regression, decision trees, random forests, support vector machines (SVM), or gradient boosting algorithms like XGBoost or LightGBM may be considered. The chosen algorithm will be trained on the preprocessed dataset, employing suitable training techniques such as cross-validation to ensure the model's robustness and generalization capabilities. By iteratively refining the model's parameters and evaluating its performance, we can develop a reliable classifier for predicting customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20260/2613075202.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Feature Selection, XAI, Feature Importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequentialFeatureSelector\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSFS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpermutation_importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "# Import modules & packages\n",
    "\n",
    "# Data manipulation \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px \n",
    "import plotly.colors as colors\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV #splitting the dataset into test-train\n",
    "from imblearn.over_sampling import SMOTE #SMOTE technique to deal with unbalanced data problem\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score,confusion_matrix,roc_curve,roc_auc_score,classification_report # performance metrics\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder # to scale the numeric features\n",
    "from scipy import stats\n",
    "\n",
    "# Feature Selection, XAI, Feature Importance\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Algorithms for supervised learning methods\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Filtering future warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from csv file & create dataframe. Checking the first 5 rows.\n",
    "df = pd.read_csv('bigml_59c28831336c6604c800002a.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of Features in the Datset**\n",
    "\n",
    "state: the state the customer lives in\n",
    "\n",
    "account length: the number of days the customer has had an account\n",
    "\n",
    "area code: the area code of the customer\n",
    "\n",
    "phone number: the phone number of the customer\n",
    "\n",
    "international plan: true if the customer has the international plan, otherwise false\n",
    "\n",
    "voice mail plan: true if the customer has the voice mail plan, otherwise false\n",
    "\n",
    "number vmail messages: the number of voicemails the customer has sent\n",
    "\n",
    "total day minutes: total number of minutes the customer has been in calls during the day\n",
    "\n",
    "total day calls: total number of calls the user has done during the day\n",
    "\n",
    "total day charge: total amount of money the customer was charged by the Telecom company for calls during the day\n",
    "\n",
    "total eve minutes: total number of minutes the customer has been in calls during the evening\n",
    "\n",
    "total eve calls: total number of calls the customer has done during the evening\n",
    "\n",
    "total eve charge: total amount of money the customer was charged by the Telecom company for calls during the evening\n",
    "\n",
    "total night minutes: total number of minutes the customer has been in calls during the night\n",
    "\n",
    "total night calls: total number of calls the customer has done during the night\n",
    "\n",
    "total night charge: total amount of money the customer was charged by the Telecom company for calls during the night\n",
    "\n",
    "total intl minutes: total number of minutes the user has been in international calls\n",
    "\n",
    "total intl calls: total number of international calls the customer has done\n",
    "\n",
    "total intl charge: total amount of money the customer was charged by the Telecom company for international calls\n",
    "\n",
    "customer service calls: number of calls the customer has made to customer service\n",
    "\n",
    "churn: true if the customer terminated their contract, otherwise false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of dataframe - 3333 rows and 21 columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Concise statistical description of numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values, no missing values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated rows, no duplicated rows to deal with.\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove customer number feature it is contact information on the client and adds no value to the analysis\n",
    "# Recheck dataframe\n",
    "df.drop(['phone number'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Continuous Features:**\n",
    "\n",
    "account length \n",
    "\n",
    "number vmail messages\n",
    "\n",
    "total day minutes\n",
    "\n",
    "total day calls\n",
    "\n",
    "total day charge\n",
    "\n",
    "total eve minutes\n",
    "\n",
    "total eve calls\n",
    "\n",
    "total eve charge\n",
    "\n",
    "total night minutes\n",
    "\n",
    "total night calls\n",
    "\n",
    "total night charge\n",
    "\n",
    "total intl minutes\n",
    "\n",
    "total intl charge\n",
    "\n",
    "customer service calls\n",
    "\n",
    "**Categorical Features:**\n",
    "\n",
    "state\n",
    "\n",
    "area code\n",
    "\n",
    "international plan\n",
    "\n",
    "voicemail plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transforming \"Churn\" Feature's Rows into 0s and 1s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['churn'] = df['churn'].map({True: 1, False: 0}).astype('int') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanatory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique values in all columns to determine feature type\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis on 'churn' Feature**\n",
    "\n",
    "Churn will be used as the dependent variable in this analysis.\n",
    "\n",
    "Churn indicates if a customer has terminated their contract with SyriaTel. True indicates they have terminated and false indicates they have not and have and have an existing account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of churn feature\n",
    "print(df.churn.value_counts())\n",
    "sns.countplot(data=df, x='churn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 3,333 customers in the dataset, 483 have terminated their contract with SyriaTel. That is 14.5% of customers lost.\n",
    "\n",
    "The distribution of the binary classes shows a data imbalance. This needs to be addressed before modeling as an unbalanced feature can cause the model to make false predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis on area code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of area code feature\n",
    "area = df['area code'].value_counts()\n",
    "transuction = area.index\n",
    "quantity = area.values\n",
    "\n",
    "# draw pie circule with plotly\n",
    "figure = px.pie(df,\n",
    "               values = quantity,\n",
    "               names = transuction,\n",
    "               hole = .5,\n",
    "               title = 'Distribution of Area Code Feature')\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half of the customers have the area code 415.\n",
    "\n",
    "One fourth of customers have the area code 510 and another fourth have the area code 408."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplot to see which area code has the highest churn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot to see which area code has the highest churn\n",
    "plt.figure(figsize=(14,5))\n",
    "sns.boxplot(data=df,x='churn',y='customer service calls',hue='area code');\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are outliers, in all area codes, amongst the customers who have not terminated their accounts.\n",
    "\n",
    "Of the customers who have terminated their account, they more likely have a 415 or a 510 area code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numeric & categorical lists\n",
    "numeric_columns = ['account length','number vmail messages','total day minutes','total day calls','total day charge',\n",
    "                'total eve minutes','total eve calls','total eve charge','total night minutes','total night calls',\n",
    "                'total night charge','total intl minutes','total intl calls','total intl charge','customer service calls']\n",
    "categoric_columns = ['state','area code','international plan','voice mail plan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distrubution Plots for Numeric Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(2,3,figsize=(19,6),constrained_layout = True)\n",
    "sns.distplot(df[\"account length\"],bins=20,ax=ax[0,0]);\n",
    "\n",
    "sns.distplot(df[\"total day calls\"],bins=20,ax=ax[0,1]);\n",
    "\n",
    "sns.distplot(df[\"total eve calls\"],bins=20,ax=ax[0,2]);\n",
    "\n",
    "sns.distplot(df[\"total night calls\"],bins=20,ax=ax[1,0]);\n",
    "\n",
    "sns.distplot(df[\"total intl calls\"],bins=20,ax=ax[1,1]);\n",
    "\n",
    "sns.distplot(df[\"customer service calls\"],bins=20,ax=ax[1,2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the distribution plots of the features above, all of them except customer service calls, have a normal distribution. Total international calls seems to be skewed to the right side however it is still normally distributed.\n",
    "\n",
    "Customer service calls has a few peaks, which indicates there are a few modes in the population. This makes sense because customer service calls has to be a integer and not a float number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Heatmap for Numeric Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = df[numeric_columns].corr()\n",
    "mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n",
    "plt.subplots(figsize=(15,12))\n",
    "sns.heatmap(corr_mat, annot=True, cmap='Blues', square=True,fmt='.0g');\n",
    "plt.xticks(rotation=90);\n",
    "plt.yticks(rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the features are not correlated however some do share a perfect correlation.\n",
    "\n",
    "Total day charge and total day minutes features are fully positively correlated.\n",
    "\n",
    "Total eve charge and total eve minutes features are fully positively correlated.\n",
    "\n",
    "Total night charge and total night minutes features are fully positively correlated.\n",
    "\n",
    "Total int charge and total int minutes features are fully positively correlated.\n",
    "\n",
    "It makes sense for these features to be perfectly correlated because the charge is a direct result of the minutes used.\n",
    "\n",
    "The perfect correlation of 1 indicates the presence of perfect multicollinearity. It does not have the same impact on nonlinear models as it does on linear models. Some nonlinear models are impacted by perfect multicollinearity whereas others are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping Highly-Correlated Features**\n",
    "\n",
    "Dropping features that have a correlation of 0.9 or above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The original dataframe has {} columns.\".format(df.shape[1]))\n",
    "# Calculate the correlation matrix and take the absolute value\n",
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "# Create a True/False mask and apply it\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "tri_df = corr_matrix.mask(mask)\n",
    "\n",
    "# List column names of highly correlated features (r > 0.90)\n",
    "to_drop = [c for c in tri_df.columns if any(tri_df[c] >  0.90)]\n",
    "\n",
    "reduced_df = df.drop(to_drop, axis=1) # Drop the features\n",
    "print(\"The reduced dataframe has {} columns.\".format(reduced_df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairplots for Numeric Features (Hue as \"Churn\")**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = df[[\"account length\",\"total day calls\",\"total eve calls\",\"total night calls\",\n",
    "                \"total intl calls\",\"customer service calls\",\"churn\"]]\n",
    "sns.pairplot(data_temp, hue=\"churn\",height=2.5);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a evident relationship between customer service calls and true churn values. After 4 calls, customers are a lot more likely to discontinue their service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical Features Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look at the churn distribution per state, to see how much the state influences our target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categoric_columns:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    sns.countplot(x=i, hue=\"churn\", data=df,order= df[i].value_counts().iloc[0:15].index)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-Hot Encoding**\n",
    "\n",
    "Transforming categorical features into dummy variables as 0 and 1 to be able to use them in classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df_area_code = pd.get_dummies(df[\"area code\"],dtype=np.int64,prefix=\"area_code_is\")\n",
    "dummy_df_international_plan = pd.get_dummies(df[\"international plan\"],dtype=np.int64,prefix=\"international_plan_is\",drop_first = True)\n",
    "dummy_df_voice_mail_plan = pd.get_dummies(df[\"voice mail plan\"],dtype=np.int64,prefix=\"voice_mail_plan_is\",drop_first = True)\n",
    "\n",
    "\n",
    "df = pd.concat([df, dummy_df_area_code, dummy_df_international_plan, dummy_df_voice_mail_plan], axis=1)\n",
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "df = df.drop(['area code', 'international plan', 'voice mail plan'],axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"state\" column is converted using the LabelEncoder, which replaces each unique label with a unique integer. In this case, a label encode is used instead of dummy variables because of the many distinct values, which when converted into dummy variables would mess up the for example the PCA and the feature importance of the tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df['state'])\n",
    "df['state'] = le.transform(df['state'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following interactive graph shows the distribution of each feature for customer with churn and for the ones without churn. The slider can be used to switch between the different features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = df[df[\"churn\"] == 1]\n",
    "no_churn = df[df[\"churn\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = colors.DEFAULT_PLOTLY_COLORS\n",
    "churn_dict = {0: \"no churn\", 1: \"churn\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_churn_trace(col, visible=False):\n",
    "    return go.Histogram(\n",
    "        x=churn[col],\n",
    "        name='churn',\n",
    "        marker = dict(color = colors[1]),\n",
    "        visible=visible,\n",
    "    )\n",
    "\n",
    "def create_no_churn_trace(col, visible=False):\n",
    "    return go.Histogram(\n",
    "        x=no_churn[col],\n",
    "        name='no churn',\n",
    "        marker = dict(color = colors[0]),\n",
    "        visible = visible,\n",
    "    )\n",
    "\n",
    "features_not_for_hist = [\"state\", \"churn\"]\n",
    "features_for_hist = [x for x in df.columns if x not in features_not_for_hist]\n",
    "active_idx = 0\n",
    "traces_churn = [(create_churn_trace(col) if i != active_idx else create_churn_trace(col, visible=True)) for i, col in enumerate(features_for_hist)]\n",
    "traces_no_churn = [(create_no_churn_trace(col) if i != active_idx else create_no_churn_trace(col, visible=True)) for i, col in enumerate(features_for_hist)]\n",
    "data = traces_churn + traces_no_churn\n",
    "\n",
    "n_features = len(features_for_hist)\n",
    "steps = []\n",
    "for i in range(n_features):\n",
    "    step = dict(\n",
    "        method = 'restyle',  \n",
    "        args = ['visible', [False] * len(data)],\n",
    "        label = features_for_hist[i],\n",
    "    )\n",
    "    step['args'][1][i] = True # Toggle i'th trace to \"visible\"\n",
    "    step['args'][1][i + n_features] = True # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "\n",
    "sliders = [dict(\n",
    "    active = active_idx,\n",
    "    currentvalue = dict(\n",
    "        prefix = \"Feature: \", \n",
    "        xanchor= 'center',\n",
    "    ),\n",
    "    pad = {\"t\": 50},\n",
    "    steps = steps,\n",
    ")]\n",
    "\n",
    "layout = dict(\n",
    "    sliders=sliders,\n",
    "    yaxis=dict(\n",
    "        title='#samples',\n",
    "        automargin=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='histogram_slider')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting histogram is of the feature \"international_plan\". While the proportion of churn for customers which have the international plan is much higher than the proportion of churn for customers without.\n",
    "\n",
    "The histograms for the \"total_day_minutes\" and \"total_day_charge\" are very similar and we can see that the customer with a higher value for these two features are more likely to churn. Interestingly, this does not apply to the number of day calls, which means that these customers seem to do longer calls. The minutes, charge and #calls for other times of the day (i.e. evening, night) do not show different distributions for customers with churn and without churn.\n",
    "\n",
    "Another interesting pattern is shown by the \"total_intl_calls\" feature. The data for the customers with churn are more left skewed than the data of the customers of the customer who did not churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, we take a look at the box plots for each feature. A box plot visualizes the following statistics**\n",
    "\n",
    "median\n",
    "the first quartile (Q1) and the third quartile (Q3) building the interquartile range (IQR)\n",
    "the lower fence (Q1 - 1.5 IQR) and the upper fence (Q3 + 1.5 IQR)\n",
    "the maximum and the minimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_box_churn_trace(col, visible=False):\n",
    "    return go.Box(\n",
    "        y=churn[col],\n",
    "        name='churn',\n",
    "        marker = dict(color = colors[1]),\n",
    "        visible=visible,\n",
    "    )\n",
    "\n",
    "def create_box_no_churn_trace(col, visible=False):\n",
    "    return go.Box(\n",
    "        y=no_churn[col],\n",
    "        name='no churn',\n",
    "        marker = dict(color = colors[0]),\n",
    "        visible = visible,\n",
    "    )\n",
    "\n",
    "features_not_for_hist = [\"state\", \"churn\"]\n",
    "features_for_hist = [x for x in df.columns if x not in features_not_for_hist]\n",
    "# remove features with too less distinct values (e.g. binary features), because boxplot does not make any sense for them\n",
    "features_for_box = [col for col in features_for_hist if len(churn[col].unique())>5]\n",
    "\n",
    "active_idx = 0\n",
    "box_traces_churn = [(create_box_churn_trace(col) if i != active_idx else create_box_churn_trace(col, visible=True)) for i, col in enumerate(features_for_box)]\n",
    "box_traces_no_churn = [(create_box_no_churn_trace(col) if i != active_idx else create_box_no_churn_trace(col, visible=True)) for i, col in enumerate(features_for_box)]\n",
    "data = box_traces_churn + box_traces_no_churn\n",
    "\n",
    "n_features = len(features_for_box)\n",
    "steps = []\n",
    "for i in range(n_features):\n",
    "    step = dict(\n",
    "        method = 'restyle',  \n",
    "        args = ['visible', [False] * len(data)],\n",
    "        label = features_for_box[i],\n",
    "    )\n",
    "    step['args'][1][i] = True # Toggle i'th trace to \"visible\"\n",
    "    step['args'][1][i + n_features] = True # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "\n",
    "sliders = [dict(\n",
    "    active = active_idx,\n",
    "    currentvalue = dict(\n",
    "        prefix = \"Feature: \", \n",
    "        xanchor= 'center',\n",
    "    ),\n",
    "    pad = {\"t\": 50},\n",
    "    steps = steps,\n",
    "    len=1,\n",
    ")]\n",
    "\n",
    "layout = dict(\n",
    "    sliders=sliders,\n",
    "    yaxis=dict(\n",
    "        title='value',\n",
    "        automargin=True,\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='box_slider')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the box plot for the number of voice mail messages (\"number_vmail_messages\"), we can see that we have some outliers for the customers with churn, but most of them have send zero voice mail messages. The customers which did not churn instead tend to do more voice mail messages.\n",
    "Similar to our findings in the histograms, we can see also in the box plot that the median of the total day minutes and the total day charge for churn clients is higher than the one of no-churn clients.\n",
    "\n",
    "Looking at the total international calls (\"total_intl_calls\"), the box plot shows that both churn and no-churn customers are doing a similar amount of international calls, but the churn-customers tend to do longer calls as the median of churn customers for the total international minutes is higher than for the no-churn customers.\n",
    "\n",
    "Finally, the plot for the number of customer service calls shows that clients with churn have a higher median and a higher variance for the customer service calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outlier Detection & Treatment**\n",
    "\n",
    "Dropping outliers past 3 standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before dropping numerical outliers, length of the dataframe is: \",len(df))\n",
    "def drop_numerical_outliers(df, z_thresh=3):\n",
    "    constrains = df.select_dtypes(include=[np.number]).apply(lambda x: np.abs(stats.zscore(x)) < z_thresh) \\\n",
    "        .all(axis=1)\n",
    "    df.drop(df.index[~constrains], inplace=True)\n",
    "    \n",
    "drop_numerical_outliers(df)\n",
    "print(\"After dropping numerical outliers, length of the dataframe is: \",len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling Numerical Features**\n",
    "\n",
    "Scaling is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, scaling the variable so the variable variance is 1, or scaling the variable so the variable values range from 0 to 1.\n",
    "\n",
    "In our example, Min-Max Normalization method is applied. MinMaxScaler is used to reduce the effects of outliers in the dataset. By applying the following method, standard deviation issues will be solved.\n",
    "MinMaxScaler is applied on the columns which is defined in \"columns_to_be_scaled\" variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = MinMaxScaler()\n",
    "\n",
    "def scaling(columns):\n",
    "    return transformer.fit_transform(df[columns].values.reshape(-1,1))\n",
    "\n",
    "for i in df.select_dtypes(include=[np.number]).columns:\n",
    "    df[i] = scaling(i)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train-Test Split**\n",
    "\n",
    "Splitting the dataset into training and testing as 75% training and 25% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['churn'],axis=1)\n",
    "y=df['churn']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying SMOTE Technique to Resolve Unbalanced 'churn' Feature**\n",
    "\n",
    "Synthetic Minority Oversampling Technique (\"SMOTE\") is an oversampling technique where synthetic samples are generated for the minority class. This algorithm helps to overcome the overfitting problem posed by random oversampling. It focuses on the feature space to generate new instances with the help of interpolation between the positive instances that lie together.\n",
    "\n",
    "The technique aims to balance class distribution by randomly increasing minority class examples by replicating them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(k_neighbors=5, random_state=123)\n",
    "X_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
    "print('Before OverSampling, the shape of X_train: {}'.format(X_train.shape))\n",
    "print('Before OverSampling, the shape of y_train: {}'.format(y_train.shape)) \n",
    "print('After OverSampling, the shape of X_train_over: {}'.format(X_train_over.shape))\n",
    "print('After OverSampling, the shape of y_train_over: {}'.format(y_train_over.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking for class imbalance again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creating a function to generate predictions, precision, recall, accuracy, and F1 score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictions(model, x_train, x_test, y_train, y_test):\n",
    "    '''Enter model name and test/train sets to generate predictions, precision, recall, accuracy, and F1 score'''\n",
    "    model.fit(x_train, y_train)\n",
    "    y_hat_train = model.predict(x_train)\n",
    "    y_hat_test = model.predict(x_test)\n",
    "    print('Training Precision: ', precision_score(y_train, y_hat_train))\n",
    "    print('Testing Precision: ', precision_score(y_test, y_hat_test))\n",
    "    print('-----')\n",
    "\n",
    "    print('Training Recall: ', recall_score(y_train, y_hat_train))\n",
    "    print('Testing Recall: ', recall_score(y_test, y_hat_test))\n",
    "    print('-----')\n",
    "\n",
    "    print('Training Accuracy: ', accuracy_score(y_train, y_hat_train))\n",
    "    print('Testing Accuracy: ', accuracy_score(y_test, y_hat_test))\n",
    "    print('-----')\n",
    "\n",
    "    print('Training F1-Score: ', f1_score(y_train, y_hat_train))\n",
    "    print('Testing F1-Score: ', f1_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**baseline Model 1 - Logistic Regression Classifier**\n",
    "\n",
    "Logistic regression is a classification algorithm, used when the value of the target variable is categorical in nature.\n",
    "\n",
    "It is most commonly used when the data in question has binary output, so when it belongs to one class or another, or is either a 0 or 1.\n",
    "This method will be used to create a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object creation, fitting the data & getting predictions \n",
    "lr_vanilla= LogisticRegression()\n",
    "lr_vanilla.fit(X_train_over,y_train_over) \n",
    "y_pred_lr_vanilla = y_pred_lr_vanilla.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lr_vanilla, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************** LOGISTIC REGRESSION vanilla CLASSIFIER MODEL RESULTS **************** \")\n",
    "print('Accuracy score for testing set: ',round(accuracy_score(y_test,y_pred_lr),5))\n",
    "print('F1 score for testing set: ',round(f1_score(y_test,y_pred_lr),5))\n",
    "print('Recall score for testing set: ',round(recall_score(y_test,y_pred_lr),5))\n",
    "print('Precision score for testing set: ',round(precision_score(y_test,y_pred_lr),5))\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "f, ax= plt.subplots(1,1,figsize=(5,3))\n",
    "sns.heatmap(cm_lr, annot=True, cmap='Blues', fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted Labels'); ax.set_ylabel('True Labels') ; ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['0', '1']) ; ax.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the logistic regression classifier model, total day charge, number of voicemail messages and total evening charge are the top three important features.\n",
    "\n",
    "Model accuracy is 76.5%, which isn't bad. F1 score is only 50.2% which means the test will only be accurate half the times it is ran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning of Logistic Regression Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-Fold Cross validated GridSearchCV hyperparameter tuning technique is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {'penalty': ['l1', 'l2'], \n",
    "             'C': np.logspace(0, 4, 5),\n",
    "             'solver' : ['lbfgs', 'newton-cg', 'liblinear','saga'],\n",
    "             'max_iter' : [5, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model2 = RandomForestClassifier()\n",
    "lr_model_GridSearchCV_Applied = GridSearchCV(rf_model2, lr_params, cv=3, n_jobs=-1, verbose=False)\n",
    "lr_model_GridSearchCV_Applied.fit(X_train_over,y_train_over)\n",
    "print(\"Best parameters:\"+str(lr_model_GridSearchCV_Applied.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets use the best hyperparameters we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_GridSearchCV_Applied = LogisticRegressionClassifier(criterion='gini', max_depth=20, max_features='sqrt', min_samples_leaf=1, min_samples_split=5, n_estimators=500)\n",
    "lr_model_GridSearchCV_Applied.fit(X_train_over,y_train_over)\n",
    "y_pred_GridSearchCV_Applied = lr_model_GridSearchCV_Applied.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************** HYPERPARAMETER TUNED linear regression MODEL RESULTS ****************\")\n",
    "print('Accuracy score for testing set: ',round(accuracy_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('F1 score for testing set: ',round(f1_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('Recall score for testing set: ',round(recall_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('Precision score for testing set: ',round(precision_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "cm_rf = confusion_matrix(y_test, y_pred_GridSearchCV_Applied)\n",
    "f, ax= plt.subplots(1,1,figsize=(5,3))\n",
    "sns.heatmap(cm_rf, annot=True, cmap='Oranges', fmt='g', ax=ax);\n",
    "ax.set_xlabel('Predicted Labels'); ax.set_ylabel('True Labels') ; ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['0', '1']) ; ax.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importance =pd.DataFrame({\"Importance\": lr_model_GridSearchCV_Applied.feature_importances_*100},index = X_train_over.columns)\n",
    "Importance.sort_values(by = \"Importance\", axis = 0, ascending = True).tail(15).plot(kind =\"barh\", color = \"r\",figsize=(9, 5))\n",
    "plt.title(\"Feature Importance Levels\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_GridSearchCV_Applied, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Models' Comparisons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_frame = pd.DataFrame({'Model':['Logistic Regression Classifier (Default)',\n",
    "                                          'Logistic Regression Classifier (GridSearchCV Applied)'],\n",
    "                                 'Accuracy (Test Set)':[0.91929,0.92434],\n",
    "                                 'F1 Score (Test Set)':[0.74194,0.7619],\n",
    "                                 'Recall (Test Set)':[0.71318,0.74419], \n",
    "                                 'Precision (Test Set)':[0.77311,0.78049]}) \n",
    "\n",
    "comparison_frame.style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2 - Random Forest Classifier**\n",
    "\n",
    "Random forest is an ensemble machine learning algorithm.\n",
    "A forest is comprised of trees. It is said that the more trees it has, the more robust a forest is. Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. It also provides a pretty good indicator of the feature importance.\n",
    "\n",
    "In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object creation, fitting the data & getting predictions \n",
    "rf_model_vanilla = RandomForestClassifier() \n",
    "rf_model_vanilla.fit(X_train_over,y_train_over) \n",
    "y_pred_rf = rf_model_vanilla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importance =pd.DataFrame({\"Importance\": rf_model_vanilla.feature_importances_*100},index = X_train_over.columns)\n",
    "Importance.sort_values(by = \"Importance\", axis = 0, ascending = True).tail(15).plot(kind =\"barh\", color = \"r\",figsize=(9, 5))\n",
    "plt.title(\"Feature Importance Levels\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rf, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************** RANDOM FOREST vanilla MODEL RESULTS **************** \")\n",
    "print('Accuracy score for testing set: ',round(accuracy_score(y_test,y_pred_rf),5))\n",
    "print('F1 score for testing set: ',round(f1_score(y_test,y_pred_rf),5))\n",
    "print('Recall score for testing set: ',round(recall_score(y_test,y_pred_rf),5))\n",
    "print('Precision score for testing set: ',round(precision_score(y_test,y_pred_rf),5))\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "f, ax= plt.subplots(1,1,figsize=(5,3))\n",
    "sns.heatmap(cm_rf, annot=True, cmap='Reds', fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted Labels'); ax.set_ylabel('True Labels') ; ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['0', '1']) ; ax.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the random forest classifier, total day charge, customer service calles and \"international plan is yes\" features have the highest impact on the model.\n",
    "\n",
    "Accuracy and F1 score are much higher for this model, which is good news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning of Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-Fold Cross validated GridSearchCV hyperparameter tuning technique is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\"max_depth\": [8,15,20],\n",
    "             \"n_estimators\":[500,1000],\n",
    "             \"min_samples_split\":[5,10,15],\n",
    "             \"min_samples_leaf\" : [1, 2, 4],\n",
    "             \"max_features\": ['auto', 'sqrt'],\n",
    "             \"criterion\":['entropy','gini']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model2 = RandomForestClassifier()\n",
    "rf_cv_model = GridSearchCV(rf_model2, rf_params, cv=3, n_jobs=-1, verbose=False)\n",
    "rf_cv_model.fit(X_train_over,y_train_over)\n",
    "print(\"Best parameters:\"+str(rf_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets use the best hyperparameters we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_GridSearchCV_Applied = RandomForestClassifier(criterion='gini', max_depth=20, max_features='sqrt', min_samples_leaf=1, min_samples_split=5, n_estimators=500)\n",
    "rf_model_GridSearchCV_Applied.fit(X_train_over,y_train_over)\n",
    "y_pred_GridSearchCV_Applied = rf_model_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************** HYPERPARAMETER TUNED RANDOM FOREST MODEL RESULTS ****************\")\n",
    "print('Accuracy score for testing set: ',round(accuracy_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('F1 score for testing set: ',round(f1_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('Recall score for testing set: ',round(recall_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('Precision score for testing set: ',round(precision_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "cm_rf = confusion_matrix(y_test, y_pred_GridSearchCV_Applied)\n",
    "f, ax= plt.subplots(1,1,figsize=(5,3))\n",
    "sns.heatmap(cm_rf, annot=True, cmap='Oranges', fmt='g', ax=ax);\n",
    "ax.set_xlabel('Predicted Labels'); ax.set_ylabel('True Labels') ; ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['0', '1']) ; ax.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importance =pd.DataFrame({\"Importance\": rf_model_GridSearchCV_Applied.feature_importances_*100},index = X_train_over.columns)\n",
    "Importance.sort_values(by = \"Importance\", axis = 0, ascending = True).tail(15).plot(kind =\"barh\", color = \"r\",figsize=(9, 5))\n",
    "plt.title(\"Feature Importance Levels\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_GridSearchCV_Applied, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Models' Comparisons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_frame = pd.DataFrame({'Model':['Random Forest Classifier (Default)',\n",
    "                                          'Random Forest Classifier (GridSearchCV Applied)'],\n",
    "                                 'Accuracy (Test Set)':[0.91929,0.92434],\n",
    "                                 'F1 Score (Test Set)':[0.74194,0.7619],\n",
    "                                 'Recall (Test Set)':[0.71318,0.74419], \n",
    "                                 'Precision (Test Set)':[0.77311,0.78049]}) \n",
    "\n",
    "comparison_frame.style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 3 - Decision Tree Classifier**\n",
    "\n",
    "Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.\n",
    "\n",
    "It is called a decision tree because, similar to a tree, it starts with the root node, which expands on further branches and constructs a tree-like structure.\n",
    "\n",
    "Decision Trees usually mimic human thinking ability while making a decision, so it is easy to understand.\n",
    "\n",
    "The logic behind the decision tree can be easily understood because it shows a tree-like structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object creation, fitting the data & getting predictions\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train_over,y_train_over)\n",
    "y_pred_dt = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_train_over.columns)\n",
    "importances = decision_tree.feature_importances_[0:15]\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='green', align='center')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_dt, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************** DECISION TREE vanilla CLASSIFIER MODEL RESULTS **************** \")\n",
    "print('Accuracy score for testing set: ',round(accuracy_score(y_test,y_pred_dt),5))\n",
    "print('F1 score for testing set: ',round(f1_score(y_test,y_pred_dt),5))\n",
    "print('Recall score for testing set: ',round(recall_score(y_test,y_pred_dt),5))\n",
    "print('Precision score for testing set: ',round(precision_score(y_test,y_pred_dt),5))\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "f, ax= plt.subplots(1,1,figsize=(5,3))\n",
    "sns.heatmap(cm_dt, annot=True, cmap='Greens', fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted Labels'); ax.set_ylabel('True Labels') ; ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['0', '1']) ; ax.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the decision tree classifier, customer service calls total day charge and total evening charge are the three most important for the model.\n",
    "\n",
    "The accuracy and F1 score for this model is not as great as model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning of Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "    'max_features': [\"sqrt\"], # just sqrt is used because values of log2 and sqrt are very similar for our number of features (10-19)\n",
    "    'min_samples_split': [6, 10, 14],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model2 = DecisionTreeClassifier()\n",
    "dt_model_GridSearchCV_Applied = GridSearchCV(dt_model2, dt_params, cv=3, n_jobs=-1, verbose=False)\n",
    "dt_model_GridSearchCV_Applied.fit(X_train_over,y_train_over)\n",
    "print(\"Best parameters:\"+str(lr_model_GridSearchCV_Applied.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets use the best hyperparameters we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model_GridSearchCV_Applied = DecisionTreeClassifier(criterion='gini', max_depth=20, max_features='sqrt', min_samples_leaf=1, min_samples_split=5, n_estimators=500)\n",
    "dt_model_GridSearchCV_Applied.fit(X_train_over,y_train_over)\n",
    "y_pred_GridSearchCV_Applied = dt_model_GridSearchCV_Applied.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************** HYPERPARAMETER TUNED Decision Tree MODEL RESULTS ****************\")\n",
    "print('Accuracy score for testing set: ',round(accuracy_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('F1 score for testing set: ',round(f1_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('Recall score for testing set: ',round(recall_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('Precision score for testing set: ',round(precision_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "cm_rf = confusion_matrix(y_test, y_pred_GridSearchCV_Applied)\n",
    "f, ax= plt.subplots(1,1,figsize=(5,3))\n",
    "sns.heatmap(cm_rf, annot=True, cmap='Oranges', fmt='g', ax=ax);\n",
    "ax.set_xlabel('Predicted Labels'); ax.set_ylabel('True Labels') ; ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['0', '1']) ; ax.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importance =pd.DataFrame({\"Importance\": dt_model_GridSearchCV_Applied.feature_importances_*100},index = X_train_over.columns)\n",
    "Importance.sort_values(by = \"Importance\", axis = 0, ascending = True).tail(15).plot(kind =\"barh\", color = \"r\",figsize=(9, 5))\n",
    "plt.title(\"Feature Importance Levels\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_GridSearchCV_Applied, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Models' Comparisons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_frame = pd.DataFrame({'Model':['Decision Tree Classifier (Default)',\n",
    "                                          'Decision Tree Classifier (GridSearchCV Applied)'],\n",
    "                                 'Accuracy (Test Set)':[0.91929,0.92434],\n",
    "                                 'F1 Score (Test Set)':[0.74194,0.7619],\n",
    "                                 'Recall (Test Set)':[0.71318,0.74419], \n",
    "                                 'Precision (Test Set)':[0.77311,0.78049]}) \n",
    "\n",
    "comparison_frame.style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 4 - K-Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN) is a simple yet powerful supervised machine learning algorithm used for classification and regression tasks. In the context of customer churn prediction for SyriaTel, KNN can be utilized to classify customers as churned or active based on similarities in their feature values.\n",
    "\n",
    "In KNN modeling, the algorithm classifies a new data point by comparing it to its K nearest neighbors in the training dataset. The value of K represents the number of neighboring data points considered for classification. The algorithm calculates the distance between the new data point and each of its neighbors using a distance metric such as Euclidean distance. The majority class among the K nearest neighbors determines the class label assigned to the new data point.\n",
    "\n",
    "One advantage of KNN is its simplicity and intuitive nature. It does not make any underlying assumptions about the data distribution and can capture nonlinear relationships between features and the target variable. \n",
    "\n",
    "The choice of K is crucial, as too low or too high values can lead to biased or noisy predictions, respectively. Additionally, KNN is sensitive to the scale of features, and feature normalization may be necessary to ensure equal importance across different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting our KNN classifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(explained_variance_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning using random search \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "neighbor_range = np.arange(1, 41)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {'n_neighbors' : neighbor_range,\n",
    "         'weights' : ['uniform', 'distance'],\n",
    "         'metric' : ['manhattan', 'euclidean', 'minkowski']}\n",
    "\n",
    "kfolds = KFold(n_splits = 5)\n",
    "rscv = RandomizedSearchCV(knn, params, random_state = 0)\n",
    "rscv.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", rscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fittng the best parameters\n",
    "knn_b = KNeighborsClassifier(n_neighbors=15, weights='distance',metric='euclidean')\n",
    "#Train model \n",
    "knn_b.fit(X_train,y_train)\n",
    "#Predict using model \n",
    "y_pred = knn_b.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knn= accuracy_score(y_test, y_pred)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(explained_variance_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning of K-Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'weights' : ['uniform', 'distance'],\n",
    "              'metric' : ['manhattan', 'euclidean', 'minkowski'],\n",
    "              'n_neighbors': [5, 15, 25, 35, 45, 55, 65],\n",
    "              'p': [1, 2, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model2 = KNeighborsClassifier()\n",
    "knn_model_GridSearchCV_Applied = GridSearchCV(dt_model2, knn_params, cv=3, n_jobs=-1, verbose=False)\n",
    "knn_model_GridSearchCV_Applied.fit(X_train_over,y_train_over)\n",
    "print(\"Best parameters:\"+str(knn_model_GridSearchCV_Applied.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets use the best hyperparameters we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model_GridSearchCV_Applied = KNeighborsClassifier(criterion='gini', max_depth=20, max_features='sqrt', min_samples_leaf=1, min_samples_split=5, n_estimators=500)\n",
    "knn_model_GridSearchCV_Applied.fit(X_train_over,y_train_over)\n",
    "y_pred_GridSearchCV_Applied = knn_model_GridSearchCV_Applied.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************** HYPERPARAMETER TUNED knn MODEL RESULTS ****************\")\n",
    "print('Accuracy score for testing set: ',round(accuracy_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('F1 score for testing set: ',round(f1_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('Recall score for testing set: ',round(recall_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('Precision score for testing set: ',round(precision_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "cm_rf = confusion_matrix(y_test, y_pred_GridSearchCV_Applied)\n",
    "f, ax= plt.subplots(1,1,figsize=(5,3))\n",
    "sns.heatmap(cm_rf, annot=True, cmap='Oranges', fmt='g', ax=ax);\n",
    "ax.set_xlabel('Predicted Labels'); ax.set_ylabel('True Labels') ; ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['0', '1']) ; ax.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importance =pd.DataFrame({\"Importance\": dt_model_GridSearchCV_Applied.feature_importances_*100},index = X_train_over.columns)\n",
    "Importance.sort_values(by = \"Importance\", axis = 0, ascending = True).tail(15).plot(kind =\"barh\", color = \"r\",figsize=(9, 5))\n",
    "plt.title(\"Feature Importance Levels\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_GridSearchCV_Applied, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**knn Models' Comparisons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_frame = pd.DataFrame({'Model':['knn Classifier (Default)',\n",
    "                                          'knn Classifier (GridSearchCV Applied)'],\n",
    "                                 'Accuracy (Test Set)':[0.91929,0.92434],\n",
    "                                 'F1 Score (Test Set)':[0.74194,0.7619],\n",
    "                                 'Recall (Test Set)':[0.71318,0.74419], \n",
    "                                 'Precision (Test Set)':[0.77311,0.78049]}) \n",
    "\n",
    "comparison_frame.style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 5 - Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM) is a powerful supervised machine learning algorithm used for classification and regression tasks. It finds an optimal hyperplane that separates data points with the largest margin, allowing it to handle high-dimensional and nonlinear data effectively. \n",
    "\n",
    "SVM utilizes support vectors, which are the data points closest to the decision boundary, to define the separation between classes. It can handle both linearly separable and nonlinear data using different kernel functions such as linear, polynomial, RBF, and sigmoid.\n",
    "\n",
    "One advantage of SVM is its ability to generalize well to unseen data and handle complex datasets. By maximizing the margin, SVM can provide good generalization performance and be less prone to overfitting. SVM is also robust against outliers due to its focus on support vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Let's now build the svm model \n",
    "model = SVC()\n",
    "# Train the model using the training set\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Predict the response for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(explained_variance_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing our model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1, 1],\n",
    "              'gamma': [1, 0.1]\n",
    "}\n",
    "svm_grid = GridSearchCV(model,param_grid=param_grid)\n",
    "svm_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svm_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the best parameters from hyperparameter tuning:\n",
    "Final= SVC(C = 1, gamma = 0.1)\n",
    "\n",
    "#Fitting the model:\n",
    "Final.fit(X_train,y_train)\n",
    "\n",
    "#Predicting values:\n",
    "y_pred = Final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Svm= accuracy_score(y_test, y_pred)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(explained_variance_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning of Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning of K-Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {'gamma': [1, 0.1],\n",
    "              'kernel': ['linear'],\n",
    "              'C': [0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model2 = SVC()\n",
    "svm_model_GridSearchCV_Applied = GridSearchCV(svm_model2, svm_params, cv=3, n_jobs=-1, verbose=False)\n",
    "svm_model_GridSearchCV_Applied.fit(X_train_over,y_train_over)\n",
    "print(\"Best parameters:\"+str(svm_model_GridSearchCV_Applied.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets use the best hyperparameters we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_GridSearchCV_Applied = SVC(criterion='gini', max_depth=20, max_features='sqrt', min_samples_leaf=1, min_samples_split=5, n_estimators=500)\n",
    "svm_model_GridSearchCV_Applied.fit(X_train_over,y_train_over)\n",
    "y_pred_GridSearchCV_Applied = svm_model_GridSearchCV_Applied.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************** HYPERPARAMETER TUNED svm MODEL RESULTS ****************\")\n",
    "print('Accuracy score for testing set: ',round(accuracy_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('F1 score for testing set: ',round(f1_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('Recall score for testing set: ',round(recall_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "print('Precision score for testing set: ',round(precision_score(y_test, y_pred_GridSearchCV_Applied),5))\n",
    "cm_rf = confusion_matrix(y_test, y_pred_GridSearchCV_Applied)\n",
    "f, ax= plt.subplots(1,1,figsize=(5,3))\n",
    "sns.heatmap(cm_rf, annot=True, cmap='Oranges', fmt='g', ax=ax);\n",
    "ax.set_xlabel('Predicted Labels'); ax.set_ylabel('True Labels') ; ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['0', '1']) ; ax.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importance =pd.DataFrame({\"Importance\": dt_model_GridSearchCV_Applied.feature_importances_*100},index = X_train_over.columns)\n",
    "Importance.sort_values(by = \"Importance\", axis = 0, ascending = True).tail(15).plot(kind =\"barh\", color = \"r\",figsize=(9, 5))\n",
    "plt.title(\"Feature Importance Levels\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_GridSearchCV_Applied, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm Models' Comparisons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_frame = pd.DataFrame({'Model':['svm Classifier (Default)',\n",
    "                                          'svm Classifier (GridSearchCV Applied)'],\n",
    "                                 'Accuracy (Test Set)':[0.91929,0.92434],\n",
    "                                 'F1 Score (Test Set)':[0.74194,0.7619],\n",
    "                                 'Recall (Test Set)':[0.71318,0.74419], \n",
    "                                 'Precision (Test Set)':[0.77311,0.78049]}) \n",
    "\n",
    "comparison_frame.style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models Comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(),\n",
    "               RandomForestClassifier(),\n",
    "               DecisionTreeClassifier(),\n",
    "              KNeighborsClassifier,\n",
    "              SVC()]\n",
    "\n",
    "\n",
    "# Define a result table as a DataFrame\n",
    "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
    "\n",
    "# Train the models and record the results\n",
    "for cls in classifiers:\n",
    "    model = cls.fit(X_train_over, y_train_over)\n",
    "    yproba = model.predict_proba(X_test)[::,1]\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "    auc = roc_auc_score(y_test, yproba)\n",
    "    \n",
    "    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n",
    "                                        'fpr':fpr, \n",
    "                                        'tpr':tpr, \n",
    "                                        'auc':auc}, ignore_index=True)\n",
    "\n",
    "# Set name of the classifiers as index labels\n",
    "result_table.set_index('classifiers', inplace=True)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "for i in result_table.index:\n",
    "    plt.plot(result_table.loc[i]['fpr'], \n",
    "             result_table.loc[i]['tpr'], \n",
    "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
    "    \n",
    "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve illustrates the true positive rate against the false positive rate of our classifier.\n",
    "\n",
    "The best performing models will have a curve that hugs the upper left of the graph, which is the the random forest classifier in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Comparisons - F1 Score (10-fold cross-validated)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr,rf_model_final,decision_tree]\n",
    "\n",
    "result = []\n",
    "results = pd.DataFrame(columns= [\"Models\",\"F1\"])\n",
    "\n",
    "for model in models:\n",
    "    names = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = cross_val_score(model,X_test,y_test,cv=10,scoring=\"f1_weighted\").mean()  \n",
    "    result = pd.DataFrame([[names, f1*100]], columns= [\"Models\",\"F1\"])\n",
    "    results = results.append(result)\n",
    "    \n",
    "sns.barplot(x= 'F1', y = 'Models', data=results, palette=\"coolwarm\")\n",
    "plt.xlabel('F1 %')\n",
    "plt.title('F1 of the models');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=\"F1\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score measures the harmonic mean between precision and recall\n",
    "\n",
    "It is a value between 0 and 1, with 1 being a perfect score and an indication everything was observed correctly.\n",
    "\n",
    "Random forest classifier had the highest F1 score. false negative have more of a business impact. need to focus on recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Comparisons - Accuracy (10-fold cross-validated)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr,rf_model_final,decision_tree]\n",
    "\n",
    "result = []\n",
    "results = pd.DataFrame(columns= [\"Models\",\"Accuracy\"])\n",
    "\n",
    "for model in models:\n",
    "    names = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)    \n",
    "    result = pd.DataFrame([[names, accuracy*100]], columns= [\"Models\",\"Accuracy\"])\n",
    "    results = results.append(result)\n",
    "    \n",
    "    \n",
    "sns.barplot(x= 'Accuracy', y = 'Models', data=results, palette=\"coolwarm\")\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Accuracy of the models');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=\"Accuracy\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy allows one to measure the total number of prediction a model gets right.\n",
    "\n",
    "The best performing model will have the highest accuracy.\n",
    "\n",
    "Of the four models tested, random forest classifier has the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying SFS (Sequential Feature Selector) Feature Selection Techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sequential Feature Selector (SFS) is a feature selection technique that iteratively selects the most relevant features for a given task. It reduces dimensionality and improves model performance by choosing features based on predefined criteria. SFS explores different feature combinations and evaluates their impact on model performance. It improves interpretability and computational efficiency by selecting informative features.\n",
    "\n",
    "During each iteration, SFS evaluates different subsets of features by training and testing a machine learning model. It considers both the individual performance of features and their interactions with other selected features. This way, SFS explores different combinations of features to identify the most informative subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=20,min_samples_split=5,n_estimators=500,criterion='entropy')\n",
    "sfs1 = SFS(rf, k_features=10, forward=True, floating=False, verbose=False,scoring='f1',cv=3,n_jobs=-1)\n",
    "sfs1 = sfs1.fit(X, y)\n",
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs1.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Model's\", sfs1.scoring, \"score is:\",round(sfs1.k_score_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(sfs1.get_metric_dict()).T.iloc[0:, 0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_sfs(sfs1.get_metric_dict(), kind='std_err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df_subsets = reduced_df[['number vmail messages',\n",
    " 'total day charge',\n",
    " 'total eve charge',\n",
    " 'total night charge',\n",
    " 'total intl charge',\n",
    " 'customer service calls',\n",
    " 'state_is_AL',\n",
    " 'state_is_HI',\n",
    " 'state_is_RI',\n",
    " 'international_plan_is_yes','churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = reduced_df_subsets.drop(['churn'],axis=1)\n",
    "y_reduced = reduced_df_subsets['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_SFS_Applied = RandomForestClassifier(max_depth=20,min_samples_split=5,n_estimators=500,criterion='entropy') \n",
    "rf_model_SFS_Applied.fit(X_train_sfs,y_train_sfs) # Fitting the data into the algorithm\n",
    "rf_model_SFS_Applied = rf_model_SFS_Applied.predict(X_test_sfs) # Getting the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************** SFS APPLIED RANDOM FOREST MODEL RESULTS **************** \")\n",
    "print('Accuracy score for testing set: ',round(accuracy_score(y_test,y_pred_rf_sfs),5))\n",
    "print('F1 score for testing set: ',round(f1_score(y_test,y_pred_rf_sfs),5))\n",
    "print('Recall score for testing set: ',round(recall_score(y_test,y_pred_rf_sfs),5))\n",
    "print('Precision score for testing set: ',round(precision_score(y_test,y_pred_rf_sfs),5))\n",
    "cm_rf_sfs = confusion_matrix(y_test, y_pred_rf_sfs)\n",
    "f, ax= plt.subplots(1,1,figsize=(5,3))\n",
    "sns.heatmap(cm_rf_sfs, annot=True, cmap='Reds', fmt='g', ax=ax);\n",
    "ax.set_xlabel('Predicted Labels'); ax.set_ylabel('True Labels') ; ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['0', '1']) ; ax.yaxis.set_ticklabels(['0', '1'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reccomendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
